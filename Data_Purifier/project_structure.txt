data_purifier/
├── __init__.py               # Initializes the Python package.
├── .env                      # Environment variables for API keys and configurations (e.g., OPENAI_API_KEY).
├── data_purification.log     # Log file for the entire data purification process, capturing detailed agent activities and errors.
├── delete_redundant_files.py # Script for deleting redundant files (e.g., temporary outputs, old logs).
├── delete_temp_files.py      # Script for deleting temporary files.
├── desktop.ini               # Windows configuration file (can be ignored).
├── folderico-fLNqcf.ico      # Icon file for the folder (can be ignored).
├── main.py                   # The main entry point of the application. Orchestrates the overall workflow.
├── meta_output.txt           # Example file for user-defined metadata, analytical questions, and initial processing instructions.
├── output.csv                # Example output file for the processed dataset in CSV format.
├── output.csv.json           # Comprehensive JSON report associated with the output.csv, detailing every step of the purification process.
├── project_structure.txt     # This file, detailing the project directory and file organization.
├── pyproject.toml            # Project configuration file (e.g., for build systems, linters like Ruff).
├── Readme.md                 # Project README file, providing an overview, setup, usage, and features.
├── requirements.txt          # Lists all Python dependencies required for the project.
├── test_openai_key.py        # Script to test the OpenAI API key configuration.
├── test_report.json          # JSON report for test runs.
├── yt.csv                    # Example input dataset in CSV format.
│
├── agents/                   # Contains the core AI agents responsible for different data processing stages.
│   ├── __pycache__/          # Python bytecode cache.
│   ├── cleaner_agent.py      # **Advanced Cleaner Agent**: Handles missing values, outliers, duplicates, and inconsistencies. Features adaptive logic for imputation (mean/median/mode based on data distribution), outlier handling (IQR/Z-score/Isolation Forest based on LLM suggestion or adaptive choice), and inconsistency resolution (adaptive fuzzy matching with case standardization).
│   ├── cleaning_validator_agent.py # Validates the output of the CleanerAgent, checking for residual issues and providing specific recommendations for re-cleaning.
│   ├── delete_cleaner_simple.py # (Potentially deprecated/simple cleaner) A basic cleaner script.
│   ├── meta_analyzer_agent.py# **Advanced Meta Analyzer Agent**: Analyzes metadata, loads data (with parallel processing for efficiency), and generates initial processing plans. Its LLM prompt is enhanced to elicit detailed justifications for suggested operations and pipeline stages. It also forces unique rows after initial loading.
│   ├── modification_validator_agent.py # Validates the output of the DataModifierAgent, ensuring modifications align with instructions and data integrity.
│   ├── modifier_agent.py     # **Advanced Data Modifier Agent**: Performs feature engineering (with adaptive age/BMI grouping), data aggregation, and column operations. Adaptive logic helps choose appropriate methods based on data characteristics.
│   ├── orchestrator_agent.py # **Orchestrator Agent**: The central agent that orchestrates the entire data purification pipeline. It dynamically delegates tasks, manages iterative refinement based on validation feedback, and integrates learned optimizations.
│   ├── process_recorder_agent.py # **Advanced Process Recorder Agent**: Logs all activities in detail, including the 'reason' behind each operation. It generates a comprehensive, human-readable final report summarizing the entire pipeline run, including data quality impacts and adaptive choices made.
│   ├── transformation_validator_agent.py # Validates the output of the TransformerAgent, ensuring transformations are correctly applied and data integrity is maintained.
│   └── transformer_agent.py  # **Advanced Transformer Agent**: Handles data transformation (scaling, encoding, text processing). Features adaptive logic for scaling (Min-Max/Standard based on skewness) and categorical encoding (One-Hot/Label/Frequency based on cardinality).
│
├── config/                   # Stores configuration-related files.
│   ├── __pycache__/          # Python bytecode cache.
│   └── settings.py           # Python script for loading application settings and environment variables, including LLM configurations.
│
├── data_purifier.egg-info/   # Metadata directory for the Python package (generated by setuptools).
│   ├── dependency_links.txt  # Lists dependency links.
│   ├── PKG-INFO              # Package metadata.
│   ├── requires.txt          # Lists package requirements.
│   ├── SOURCES.txt           # Lists all source files in the package.
│   └── top_level.txt         # Lists top-level modules in the package.
│
├── tests/                    # Contains unit and integration tests for the project.
│   ├── __pycache__/          # Python bytecode cache.
│   ├── __init__.py           # Initializes the tests package.
│   ├── conftest.py           # Pytest configuration and fixtures.
│   ├── run_tests.py          # Script to run the test suite.
│   ├── test_cleaner.py       # Unit tests for the CleanerAgent.
│   ├── test_integration.py   # Integration tests for the overall pipeline flow.
│   ├── test_meta_analyzer.py # Unit tests for the MetaAnalyzerAgent.
│   ├── test_modifier.py      # Unit tests for the DataModifierAgent.
│   ├── test_recorder.py      # Unit tests for the ProcessRecorderAgent.
│   └── test_transformer.py   # Unit tests for the TransformerAgent.
│
└── utils/                    # Contains utility functions and helper scripts.
    ├── __pycache__/          # Python bytecode cache.
    └── report_generator.py   # Utility for generating various reports (e.g., HTML reports).